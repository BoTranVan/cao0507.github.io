<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>虚拟化技术与云计算平台报告</title>
      <link href="/2018/03/22/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E6%8A%A5%E5%91%8A/"/>
      <url>/2018/03/22/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E6%8A%A5%E5%91%8A/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从2006年谷歌首次提出“云计算”的概念到现在，云计算已经经历的十多年的发展，有众多厂商、组织和学者投入其中。一些云服务厂商有自己的云计算平台，但只是为客户提供云服务，外部开发者无法对这些厂商的云平台进行开发。另外也有一些组织机构或厂商开发的云计算平台是开源的，吸引大量开发者在这些开源平台上开展自己的工作。</p><a id="more"></a><p>目前，主流的开源云计算平台有很多种，本问将对这些平台进行调研以选择最适合于自己需求的平台。另外，虚拟化技术又是云计算的核心支撑技术，是将各种计算及存储资源充分整合和高效利用的关键技术，当前虚拟化技术也是多种多样，并且开源云计算平台往往又支持多种底层的虚拟化技术，因此也有必要对虚拟化技术进行调研，以选择最适合云平台和上层应用的虚拟化技术。综上，本报告的主要目标就是对多种虚拟化技术和多种开源云计算平台进行对比，以选出最满足需求的技术与平台。</p><p>本文将首先简单对比虚拟化与云计算。其后，由于虚拟化技术是云计算的基础，本报告将先对虚拟化技术展开论述，然后再对云计算平台进行论述。</p><h1 id="虚拟化与云计算"><a href="#虚拟化与云计算" class="headerlink" title="虚拟化与云计算"></a>虚拟化与云计算</h1><p>借助虚拟化技术，用户可以单个物理硬件系统为基础创建多个模拟环境或专用资源。并使用一款名为“Hypervisor”(虚拟机监控程序)的软件直接连接到硬件，从而将一个系统划分为不同的、单独安全环境，即虚拟机 (VM)。Hypervisor 能够将计算机资源与硬件分离并适当分配资源，而虚拟机则依赖这些功能运行。</p><p>云计算则由多种规则和方法组合而成，可以跨任何网络向用户按需提供计算、网络和存储基础架构资源、服务、平台和应用。这些基础架构资源、服务和应用来源于云。 简单来讲，云就是一系列管理及自动化软件编排而成的虚拟资源池，旨在帮助用户通过支持自动扩展和动态资源分配的自助服务门户，按需对这些资源进行访问。</p><p>下面对虚拟化与云计算做一个简单的对比：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">虚拟化</th><th style="text-align:center">云</th></tr></thead><tbody><tr><td style="text-align:center">定义</td><td style="text-align:center">技术</td><td style="text-align:center">方法论</td></tr><tr><td style="text-align:center">目的</td><td style="text-align:center">从一个物理硬件系统创建多个虚拟环境</td><td style="text-align:center">汇聚并自动化分配虚拟资源以供按需使用</td></tr><tr><td style="text-align:center">用途</td><td style="text-align:center">针对具体用途为特定用户提供打包资源</td><td style="text-align:center">针对多种用途为用户群组提供不同资源</td></tr><tr><td style="text-align:center">使用寿命</td><td style="text-align:center">数年（长期）</td><td style="text-align:center">数小时至数月</td></tr><tr><td style="text-align:center">成本</td><td style="text-align:center">资本支出（CAPEX）高<br>运营支出（OPEX）低</td><td style="text-align:center">共有云：CAPEX高、OPEX低<br>私有云：CAPEX低、OPEX高</td></tr><tr><td style="text-align:center">可扩展性</td><td style="text-align:center">纵向扩展</td><td style="text-align:center">横向扩展</td></tr><tr><td style="text-align:center">工作负载</td><td style="text-align:center">有状态</td><td style="text-align:center">无状态</td></tr><tr><td style="text-align:center">租赁</td><td style="text-align:center">单一租户</td><td style="text-align:center">多个租户</td></tr></tbody></table><h1 id="虚拟化技术"><a href="#虚拟化技术" class="headerlink" title="虚拟化技术"></a>虚拟化技术</h1><p>按照虚拟化的对象分类，虚拟化可分为服务器虚拟化、操作系统虚拟化、存储虚拟化、网络虚拟化等。其中服务器虚拟化对CPU、内存、设备与I/O这三种硬件资源的虚拟化技术已经相当成熟，但对GPU的虚拟化却还有很大的提升空间。下面将分别介绍服务器虚拟化中CPU虚拟化及GPU虚拟化相关的技术，然后对现在主流的虚拟化平台做一些比较。</p><h2 id="一、CPU虚拟化"><a href="#一、CPU虚拟化" class="headerlink" title="一、CPU虚拟化"></a>一、CPU虚拟化</h2><p>目前，为了解决x86体系结构下的CPU虚拟化问题，业界提出了全虚拟化和半虚拟化两种不同的软件方案。除了通过软件的方式实现CPU虚拟化外，业界还提出了在硬件层添加支持功能的硬件辅助虚拟化方案来处理那些敏感的高级别指令。</p><p>全虚拟化在宿主机底层物理硬件与VM之间增加一个软件层，即虚拟机监控器（VMM或hypervisor），此时，VMM充当主机操作系统，用来管理不同的虚拟机，如图1所示。它隐藏了特定计算平台的实际物理特性，为用户提供抽象的、统一的、模拟的计算环境（称为虚拟机）。在VMM平台上，可以模拟出多套虚拟机，实现了在单机上运行多个不同类型操作系统的虚拟机。全虚拟化的优点是不需要修改客户机操作系统，因此支持多种操作系统，缺点是VMM层工作负荷较大，并占用一定的宿主机资源，性能不如裸机。主要代表有VMware vSphere，Microsoft公司的Virtual PC、Redhat公司的RED HAT ENTERPRISE VIRTUALIZATION等。 </p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/%E5%85%A8%E8%99%9A%E6%8B%9F%E5%8C%96%E6%9E%B6%E6%9E%84.png" alt="全虚拟化架构"></p><p>半虚拟化与全虚拟化类似，不同之处是需要修改客户机操作系统的核心代码，即增加一个专门的虚拟化应用程序接口，优化客户操作系统发出的指令，与VMM能够协同工作，以减轻VMM和宿主机的负担，进一步提升了虚拟机的性能，如图2所示。缺点是需要修改客户操作系统，影响了技术的普及。主要代表有使用开源虚拟化技术的Citrix的Xenserver、Microsoft的Hyper-V 。</p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/%E5%8D%8A%E8%99%9A%E6%8B%9F%E5%8C%96%E6%9E%B6%E6%9E%84.png" alt="半虚拟化架构"></p><p>为了更好地实现全、半虚拟化技术，Intel与AMD对传统X86架构进行改进，分别设计了Intel-VT和AMD-V CPU硬件辅助虚拟化技术。将原来的特权等级Ring 0、1、2、3 定义为Non-Root mode，新增了一个Root mode 特权等级（或称为Ring -1），这种情况下，OS 即可运行在原来Ring0 的等级，而VMM 则调整到更底层的Root Mode 等级，其架构如图3。硬件辅助虚拟化有效地解决了虚拟机效率低的问题，它使虚拟机可以运行ring 0 的指令，不用再进行操作系统的ring 切换，提高了虚拟机的整体效率。 现在主流的半、全虚拟化产品都支持硬件辅助虚拟化，代表有Oracle公司的VirtualBox、RHEV、VMware vSphere和Xneserver。</p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/%E7%A1%AC%E4%BB%B6%E8%BE%85%E5%8A%A9%E8%99%9A%E6%8B%9F%E5%8C%96%E6%9E%B6%E6%9E%84.png" alt="硬件辅助虚拟化"></p><h2 id="二、GPU虚拟化"><a href="#二、GPU虚拟化" class="headerlink" title="二、GPU虚拟化"></a>二、GPU虚拟化</h2><p>GPU虚拟化相关技术还垄断在少数厂商手中，并没有像CPU、内存、存储一样在开源社区推广普及。下面将介绍三大显卡厂商GPU虚拟化的发展。</p><p>NVIDIA，早在2013年，NVIDIA就推出了行业内第一款GPU虚拟化显卡GRID K1/K2，同期联合Citrix推出了商用的vGPU虚拟桌面解决方案，这比AMD提前了近3年。GPU虚拟化技术的出现，给一直被诟病性能不足的桌面虚拟化带来了转机。在2016年，NVIDIA推出第二款GPU虚拟化显卡，Maxwell架构的Tesla M6/M10/M60，新版的GRID将使用授权分为 3 个不同版本，依据版本不同收取额外软件授权使用费。 在2017年8月份NVIDIA推出了最新版GRID 5.0，虚拟化显卡新增Pascal架构的Tesla P4/P6/P40/P100，其中Quadro Virtual Datacenter Workstation版的授权支持vGPU在图形渲染模式和高性能计算模式之间切换，这是硬件厂商首次在vGPU层面将图形渲染和高性能计算进行了统一，又一次引领了行业趋势和市场需求。NVIDIA的虚拟化显卡只是硬件，还需要相应的服务器虚拟化系统的支持，这和Intel的CPU需要操作系统Windows和Linux来配合一样。现在只有Xen和ESXi能够支持GRID virtual GPU solution，被大量第三方厂商采用的KVM虚拟化平台还没有出现在GRID的支持列表中，因此可以说GPU另外一只脚还没能踏进云计算时代。2017年7月份NVIDIA和Nutanix宣布将合作在年底推出AHV版本的GRID，这算是KVM虚拟化走出了第 一步。在解决GPU虚拟化后，如何将虚拟机的画面传送到客户端，这是KVM虚拟化可以商用的第二步。KVM上默认配置的Spice协议对3D的支持并不好，Nutanix以及其他KVM方案解决商还需自行开发出可用的桌面传输协议，这才算是彻底完成了GRID在KVM上的应用。</p><p>AMD，AMD在NVIDIA推出GRID K1/K2 的两年半后才推出了自己的GPU虚拟化产品MxGPU，算是姗姗来迟。共有三款FirePro S系列的GPU支持MxGPU，一块GPU最多可以支持 32 个用户。当MxGPU上的虚拟机比较少时，能够达到图形工作站的性能。随着虚拟机数量增多，每个虚拟机获得的GPU性能逐步降低。有别于NVIDIA GRID通过软件实现的显卡虚拟化方式，AMD MxGPU是“全球首款基于硬件的虚拟化GPU解决方案”。MxGPU每个虚拟机能分得一定数量的独享流处理器和显存空间，这样可以避免不同虚拟机对GPU资源的抢夺，造成用户噪音。这种噪音问题直到今年8月底推出NVIDIA GRID 5. 0 才得到解决。MxGPU在定价上采用的是更符合买方逻辑的营销方法，只向用户收取需付硬件的购买费用。不过遗憾的是，目前只有VMware的ESXi支持MxGPU，Xen暂时只有技术验证版。没能同时支持两种主流化的虚拟化系统，一定程度上阻碍了MxGPU在市场的普及速度。Citrix的用户还是可以用过vSphere+XenDesktop的方案用上MxGPU，相比使用免费的XenServer，要多支付vSphere的费用。</p><p>Intel，Intel官方将不同的Intel GPU虚拟化技术分别命名为Intel GVT-s，Intel GVT-d和Intel GVT-g，分布对应API转发，直通，完全虚拟化。Intel GVT-g和NVIDIA vGPU类似，支持Xen/KVM平台，每个GPU最多能分享给7个用户同时使用。其中XenGT在 2016 年最早实现了业界的vGPU在线迁移，NVIDIA GRID直到这个季度才和Citrix合作完成了vGPU在线迁移。 2016 年的 2017 年2月份，Linux 4.10中加入Intel GVT-g for KVM。这是三大GPU厂商中，第一个支持KVM平台的完全虚拟化方案，意味着第三方采用KVM的云计算厂商终于有了一个可用的vGPU方案。不过Intel GPU虚拟化，由于核显性能的原因，只能满足图像密集型的用户体验，不能像GRID vGPU和MxGPU一样满足图形渲染的重度使用场景。Intel GPU虽然支持了大多数虚拟化桌面厂商使用的Xen/KVM两大类服务器虚拟化系统，可是硬件却和VDI高密度的使用场景不太搭。首先Intel的完全虚拟化只支持Broadwell架构以后的核芯显卡，作为VDI服务器中常用的Xeon E5/E7 v4 系列，以及第 一个的Xeon Scalable处理器，都没有核芯显卡。这在很大程度上限定了Intel GPU虚拟化在VDI的使用规模，有种落入有枪无弹的尴尬境地。</p><h2 id="三、虚拟化平台比较"><a href="#三、虚拟化平台比较" class="headerlink" title="三、虚拟化平台比较"></a>三、虚拟化平台比较</h2><p>服务器虚拟化技术日益成熟，并具有广泛的应用前景，目前有很多厂商进行虚拟化技术产品的开发和生产，包括：VMware、Microsoft、Citrix、IBM和RedHat等，其各自产品都有不同的特点，产品功能日益强大。下面将比较一下四种主流服务器虚拟化平台，如下表 ：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">VMware</th><th style="text-align:center">Xen</th><th style="text-align:center">KVM</th><th style="text-align:center">Hyper-V</th></tr></thead><tbody><tr><td style="text-align:center">厂商</td><td style="text-align:center">VMware</td><td style="text-align:center">Citrix</td><td style="text-align:center">Red Hat</td><td style="text-align:center">Microsoft</td></tr><tr><td style="text-align:center">是否免费</td><td style="text-align:center">付费</td><td style="text-align:center">开源免费</td><td style="text-align:center">开源免费</td><td style="text-align:center">付费</td></tr><tr><td style="text-align:center">宿主机系统</td><td style="text-align:center">Windows<br>Linux</td><td style="text-align:center">NetBSD<br>Linux<br>Solaris</td><td style="text-align:center">Linux</td><td style="text-align:center">Windows server 2008及以上系统</td></tr><tr><td style="text-align:center">客户机系统</td><td style="text-align:center">Windows 2003、Windows 2008、RedHat、Debian、Ubuntu、Centos</td><td style="text-align:center">Xen-PV：纯Linux；Xen-HVM：支持Windows、Linux</td><td style="text-align:center">Linux、Windows</td><td style="text-align:center">Windows系列、Linux</td></tr><tr><td style="text-align:center">支持技术</td><td style="text-align:center">硬件辅助虚拟化（全虚拟化）</td><td style="text-align:center">硬件辅助虚拟化（HVM全虚拟化、PV半虚拟化）</td><td style="text-align:center">硬件辅助虚拟化（全虚拟化）</td><td style="text-align:center">硬件辅助虚拟化（半虚拟化）</td></tr><tr><td style="text-align:center">支持的vGPU产品</td><td style="text-align:center">NVIDIA GRID<br>AMD MxGPU</td><td style="text-align:center">NVIDIA GRID<br>AMD MxGPU（技术验证版）</td><td style="text-align:center">Intel GVT-g for KVM</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">优点</td><td style="text-align:center">相对成熟的商业软件，市场占有率较大</td><td style="text-align:center">性能较好，支持半虚拟化</td><td style="text-align:center">是内核本身的一部分，因此可以利用内核的优化和改进；高性能，稳定，无需修改客户机系统</td><td style="text-align:center">对Windows的支持较好</td></tr><tr><td style="text-align:center">缺点</td><td style="text-align:center">不开源，费用较高</td><td style="text-align:center">操作复杂，维护成本较高，目前已被RedHat抛弃</td><td style="text-align:center">虚拟机性能比Xen略低</td><td style="text-align:center">对Linux的支持较差，性能损失大</td></tr></tbody></table><p>开源云计算平台Openstack对这四种虚拟化平台都有支持，默认使用的是KVM，Openstack与KVM结合的方案也已经相当成熟。另外，考虑到KVM是开源免费的虚拟化技术；宿主机系统支持绝大多数Linux系统，对于使用Linux系统的服务器都有很好的支持；而客户机操作系统不仅支持Linux，还支持Windows，可以满足绝大多数用户的需求，因此选择KVM作为Openstack底层的虚拟化技术的理由是很充分的。不过，KVM对于虚拟GPU的支持不是很好，只有Intel GVT-g for KVM可以支持KVM平台的全虚拟化方案，但是Intel GPU虚拟化由于核显性能的原因，只能满足图像密集型的用户体验，不能满足图形渲染等重度使用的场景。</p><h1 id="云计算平台"><a href="#云计算平台" class="headerlink" title="云计算平台"></a>云计算平台</h1><p>目前已经有多个云计算平台的开源实现，主要的开源云计算项目有Openstack、Eucalyptus、CloudStack和OpenNebula等，现比较如下：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Openstack</th><th style="text-align:center">Eucalyptus</th><th style="text-align:center">CloudStack</th><th style="text-align:center">OpenNebula</th></tr></thead><tbody><tr><td style="text-align:center">发布时间</td><td style="text-align:center">2010年7月</td><td style="text-align:center">2008年5月</td><td style="text-align:center">2010年5月</td><td style="text-align:center">2008年7月</td></tr><tr><td style="text-align:center">最新版本</td><td style="text-align:center">Queens</td><td style="text-align:center">4.4</td><td style="text-align:center">4.11</td><td style="text-align:center">5.4</td></tr><tr><td style="text-align:center">授权协议</td><td style="text-align:center">Apache v2.0</td><td style="text-align:center">GPL v3.0</td><td style="text-align:center">Apache v2.0</td><td style="text-align:center">Apache v2.0</td></tr><tr><td style="text-align:center">基本架构</td><td style="text-align:center">Nova、Glance、Neutron、Keystone、Horizon、swift、Tacker等</td><td style="text-align:center">Cloud Controller、Cluster Controller、Node Controller、Walrus、 Storage Controller</td><td style="text-align:center">主要包括管理服务、云基础设施和网络三大部分</td><td style="text-align:center">主要包括接口与API、用户与组、主机、网络、存储、集群6个部分</td></tr><tr><td style="text-align:center">虚拟化技术支持</td><td style="text-align:center">KVM、LXC、QEMU、UML、Vmware ESX/ESXi、Xen、Hyper-V</td><td style="text-align:center">Xen、KVM、ESXi</td><td style="text-align:center">KVM、Xen、ESXi、OVM、Baremetal</td><td style="text-align:center">Xen、KVM、Vmware</td></tr><tr><td style="text-align:center">用户界面</td><td style="text-align:center">Dashboard，较简单</td><td style="text-align:center">web界面</td><td style="text-align:center">Web Console，功能较完善</td><td style="text-align:center">web界面</td></tr><tr><td style="text-align:center">社区活跃程度</td><td style="text-align:center">人数多，活跃用户数最多</td><td style="text-align:center">人数多，但活跃用户数较少</td><td style="text-align:center">人数少，但活跃用户数较多</td><td style="text-align:center">人数较少，活跃用户数也少</td></tr><tr><td style="text-align:center">兼容云平台</td><td style="text-align:center">Amazon EC2，S3</td><td style="text-align:center">Amazon EC2，S3</td><td style="text-align:center">Amazon EC2，S3</td><td style="text-align:center">Amazon EC2，S3</td></tr><tr><td style="text-align:center">开发主导</td><td style="text-align:center">开源社区</td><td style="text-align:center">Eucalyptus System Inc</td><td style="text-align:center">Citrix公司</td><td style="text-align:center">开源社区</td></tr><tr><td style="text-align:center">主要支持厂商</td><td style="text-align:center">160家左右，包括NASA、Rackspace、HP、Dell、UnitedStack等</td><td style="text-align:center">亚马逊、戴尔、惠普、Intel、Redhat、Vmware等</td><td style="text-align:center">不到60家，包括诺基亚、日本电话电报公司、阿尔卡特、迪士尼等</td><td style="text-align:center">IBM、Akamai、Blackberry、Fuze、Telefonica、Indigital</td></tr><tr><td style="text-align:center">官方文档</td><td style="text-align:center">非常详细</td><td style="text-align:center">不够详细</td><td style="text-align:center">详细</td><td style="text-align:center">详细</td></tr><tr><td style="text-align:center">检测和审计</td><td style="text-align:center">Telemetry Service</td><td style="text-align:center">Accounting system</td><td style="text-align:center">Event/Audit logs</td><td style="text-align:center">Accounting system、periodically-Monitoring</td></tr><tr><td style="text-align:center">数据库</td><td style="text-align:center">PostareSQL、MySQL、SQLite</td><td style="text-align:center">HyperSQL Database</td><td style="text-align:center">MySQL</td><td style="text-align:center">SQLite、MySQL</td></tr><tr><td style="text-align:center">部署</td><td style="text-align:center">私有云、共有云、混合云</td><td style="text-align:center">私有云、混合云</td><td style="text-align:center">私有云、共有云、混合云</td><td style="text-align:center">私有云、共有云、混合云</td></tr><tr><td style="text-align:center">操作系统</td><td style="text-align:center">Debian 7.0、openSUSE、SUSE、Red Hat、CentOS、Fedora、Ubuntu</td><td style="text-align:center">CentOS、RHEL</td><td style="text-align:center">CentOS、RHEL6.3+、Ubuntu</td><td style="text-align:center">Red Hat、Ubuntu、SUSE、CentOS、Debian</td></tr><tr><td style="text-align:center">开发语言</td><td style="text-align:center">Python</td><td style="text-align:center">Java、C/C++</td><td style="text-align:center">Java</td><td style="text-align:center">C、Ruby、shell</td></tr><tr><td style="text-align:center">开源市场部署比例</td><td style="text-align:center">69%</td><td style="text-align:center">3%</td><td style="text-align:center">14%</td><td style="text-align:center">无统计数据</td></tr></tbody></table><p>这四种主流的开源云计算平台都经过了近十年的发展，更新迭代了很多版本，能够从众多云计算平台的竞争中存活下来，都有相应的支持厂商和用户，说明它们各有各的特点，如在开发语言上就各有特色，Openstack使用的是Python语言，Eucalyptus使用Java、C/C++，CloudStack仅使用Java，而OpenNebula却显得比较奇怪，使用的是C语言、Ruby和shell，多种语言混杂而成。但不同平台之间还是有较大差距，从结果来看，在开源市场的部署比例，Openstack 69%的比例占据了绝对统治地位，Openstack能占据这样的地位有多方面的原因，如Openstack支持绝大多数的虚拟化技术，支持的操作系统也很多，使得Openstack具有广阔的应用范围；Openstack的官方文档非常详细，也降低了其学习成本；Openstack具有一个充满活力的开源社区，开发者不断为Openstack的发展作出贡献；OpenStack的支持厂商有160家左右，有如此多的厂商支持，给OpenStack的发展提供了根本保障。综合以上多方面的原因，本项目采用Openstack作为底层的云计算平台为上层提供基础设施资源也是理所当然的。另外，在2018年2月28日发布的Openstack Queens最新版本中，新引入的Marquee功能正是为了提供对vGPU的内置支持能力，这意味着用户能够将GPU添加至虚拟机中，为本项目的上层应用，如深度学习等需要强大GPU运算能力的应用提供了支持。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过以上的分析，能够清楚的了解各种虚拟化技术及各种云计算平台的差异，对于要选择满足自己需求的技术与平台会有一些帮助。</p><hr>]]></content>
      
      <categories>
          
          <category> 云计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
            <tag> Openstack </tag>
            
            <tag> 云计算 </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>KVM虚拟机部署openstack的网络配置</title>
      <link href="/2017/12/03/KVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2openstack%E7%9A%84%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"/>
      <url>/2017/12/03/KVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2openstack%E7%9A%84%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>这篇文章记录的是按照官方文档在<strong>KVM环境</strong>下部署<strong>双节点openstack</strong>过程中，前期准备KVM环境和网络配置相关的内容，在完成这篇博客涉及到的工作之后就可以按照官方文档手动安装openstack了。本文涉及的主要工作，首先是在服务器的<strong>ubuntu 16.04 desktop版</strong>系统上搭建kvm环境，然后在服务器上安装VNC远程桌面，最后在KVM环境中开启两台虚拟机，分别两张网卡，第一张网卡使用<strong>桥接模式</strong>，第二张网卡使用<strong>NAT模式</strong>。下面开始介绍一下这个过程。</p><a id="more"></a><h1 id="服务器搭建KVM环境"><a href="#服务器搭建KVM环境" class="headerlink" title="服务器搭建KVM环境"></a>服务器搭建KVM环境</h1><h2 id="查看CPU是否支持KVM"><a href="#查看CPU是否支持KVM" class="headerlink" title="查看CPU是否支持KVM"></a>查看CPU是否支持KVM</h2><p><code>$ egrep -c &quot;(svm|vmx)&quot; /proc/cpuinfo</code></p><p>输出结果大于0证明CPU支持KVM虚拟化 </p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/infocpu.png" alt="虚拟CPU个数"></p><h2 id="安装KVM及相关依赖包"><a href="#安装KVM及相关依赖包" class="headerlink" title="安装KVM及相关依赖包"></a>安装KVM及相关依赖包</h2><p><code>$ sudo apt-get install qemu-kvm qemu virt-manager virt-viewer libvirt-bin bridge-utils</code></p><h2 id="启用桥接网络"><a href="#启用桥接网络" class="headerlink" title="启用桥接网络"></a>启用桥接网络</h2><p>在服务器上启用桥接网络需要配置一个桥接设备br0，配置br0有两种方式，通过手动配置和通过修改文件配置。 </p><h3 id="通过手动配置"><a href="#通过手动配置" class="headerlink" title="通过手动配置"></a>通过手动配置</h3><ul><li><p>创建br0网桥</p><p> <code># brctl addbr br0</code></p></li><li><p>将eth0网卡添加到br0上，此时可能会断网</p><p><code># brctl addif br0 eth0</code></p></li><li><p>删除eth0上的IP地址</p><p><code># ip addr del dev eth0 192.168.1.25/24</code></p></li><li><p>配置br0的IP地址并启动br0网桥设备</p><p><code># ifconfig br0 192.168.1.25/24 up</code></p></li><li><p>重新加入默认网关</p><p><code># route add default gw 192.168.1.1</code></p></li><li><p>查看配置是否生效 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># route     //查看默认网关，输出结果如下</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination             Gateway             Genmask         Flags     Metric      Ref    Use     Iface</span><br><span class="line">default              192.168.1.1             0.0.0.0          UG        0          0      0        br0</span><br><span class="line">192.168.1.0             *                 255.255.255.0       U         0          0      0        br0</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># ifconfig     //查看eth0和br0的IP信息，输出结果如下，可以发现现在br0有IP而eth0没有IP了</span><br><span class="line">br0       Link encap:Ethernet  HWaddr 00:e0:81:e2:3c:3d  </span><br><span class="line">          inet addr:192.168.1.25  Bcast:192.168.1.255  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::2e0:81ff:fee2:3c3d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:1316822 errors:0 dropped:5787 overruns:0 frame:0</span><br><span class="line">          TX packets:365475 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000</span><br><span class="line">          RX bytes:581279124 (581.2 MB)  TX bytes:562586852 (562.5 MB)</span><br><span class="line"> </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 00:e0:81:e2:3c:3d  </span><br><span class="line">          inet6 addr: fe80::2e0:81ff:fee2:3c3d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:6671034 errors:0 dropped:9627 overruns:0 frame:0</span><br><span class="line">          TX packets:840972 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000</span><br><span class="line">          RX bytes:1346523816 (1.3 GB)  TX bytes:614510541 (614.5 MB)</span><br><span class="line">          Memory:dfb80000-dfbfffff</span><br><span class="line"> </span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:1450290 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:1450290 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000</span><br><span class="line">          RX bytes:24027042487 (24.0 GB)  TX bytes:24027042487 (24.0 GB)</span><br></pre></td></tr></table></figure></li></ul><p>这就是通过手动来配置桥接设备br0的方法，这种方法在配置好之后马上就生效了，但是在系统重启之后这些配置信息都会被清除，要想使配置永久生效则需要修改网络配置文件，也就是下面的方法。 </p><h3 id="通过修改文件配置"><a href="#通过修改文件配置" class="headerlink" title="通过修改文件配置"></a>通过修改文件配置</h3><ul><li><p>修改前先将网络配置文件进行备份</p><p><code># cp  /etc/network/interfaces  /etc/network/interfaces.bak</code></p></li><li><p>修改网络配置文件<code>/etc/network/interfaces</code></p><p><code># vi  /etc/network/interfaces    //修改结果如下</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">auto lo</span><br><span class="line">iface lo inet loopback</span><br><span class="line"> </span><br><span class="line"># Enabing Bridge networking br0 interface</span><br><span class="line">auto br0</span><br><span class="line">iface br0 inet static</span><br><span class="line">address 192.168.1.25</span><br><span class="line">network 192.168.1.0</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">broadcast 192.168.1.255</span><br><span class="line">gateway 192.168.1.1</span><br><span class="line">dns-nameservers 223.5.5.5</span><br><span class="line">bridge_ports eth0</span><br><span class="line">bridge_stp off</span><br></pre></td></tr></table></figure></li></ul><p>保存后退出，关机重启中配置文件就生效了。这种方法只需要修改配置文件然后重启就可以，比较简单，而且是永久生效，比较符合我们的需求，因为我们的虚拟机通过桥接模式连接外网的话都是连接到br0上的。 </p><h2 id="修改virbr0的网段"><a href="#修改virbr0的网段" class="headerlink" title="修改virbr0的网段"></a>修改virbr0的网段</h2><p>在服务器上安装好虚拟化软件后，KVM会自动生成一个<code>virbr0</code>的桥接设备，它的作用是为连接其上的虚拟网卡提供NAT访问外网的功能，并提供DHCP服务。<code>virbr0</code>默认分配的IP是<code>192.168.122.1</code>，使用 <code>ifconfig</code> 命令查看得<code>virbr0</code>的信息如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$  ifconfig</span><br><span class="line">……</span><br><span class="line"> </span><br><span class="line">virbr0    Link encap:Ethernet  HWaddr 52:54:00:f8:70:e3  </span><br><span class="line">          inet addr:192.168.122.1  Bcast:192.168.122.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000</span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p> 在这种情况下，连接到virbr0上的虚拟机的虚拟网卡也是在192.168.122.0网段上的，如果让连接到virbr0上的虚拟网卡在自定义的网段上就需要修改virbr0的网段，修改方法如下： </p><p><code># virsh  net-edit  default</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;network&gt;</span><br><span class="line">  &lt;name&gt;default&lt;/name&gt;</span><br><span class="line">  &lt;uuid&gt;91cc230a-bf53-487c-b296-10323705d7e8&lt;/uuid&gt;</span><br><span class="line">  &lt;forward mode=&apos;nat&apos;/&gt;</span><br><span class="line">  &lt;bridge name=&apos;virbr0&apos; stp=&apos;on&apos; delay=&apos;0&apos;/&gt;</span><br><span class="line">  &lt;mac address=&apos;52:54:00:f8:70:e3&apos;/&gt;</span><br><span class="line">  &lt;ip address=&apos;10.0.0.1&apos; netmask=&apos;255.255.255.0&apos;&gt;</span><br><span class="line">    &lt;dhcp&gt;</span><br><span class="line">      &lt;range start=&apos;10.0.0.2&apos; end=&apos;10.0.0.254&apos;/&gt;</span><br><span class="line">    &lt;/dhcp&gt;</span><br><span class="line">  &lt;/ip&gt;</span><br><span class="line">&lt;/network&gt;</span><br></pre></td></tr></table></figure><p>这样就将<code>virbr0</code>的网段改成<code>10.0.0.0/24</code>，连接到<code>virbr0</code>的虚拟网卡的IP将会在<code>10.0.0.2/24 - 10.0.0.254/24</code>范围内自动分配一个。如果有需要可以自己手动给虚拟网卡配置IP并写到配置文件中去。 </p><h1 id="服务器安装VNC远程桌面"><a href="#服务器安装VNC远程桌面" class="headerlink" title="服务器安装VNC远程桌面"></a>服务器安装VNC远程桌面</h1><p>因为服务器上安装的<code>Ubuntu 16.04 LTS  desktop</code>版的系统，在后续的工作中需要远程登录到服务器，虽然可以通过SSH远程管理服务器，但是可视化的界面往往会给新手用户提供很大的便利，所以可以在服务器上安装VNC。开始在服务器上安装VNC试过很多方法，VNC服务器端也有多种选择，如<code>VNC4server</code>、<code>tigervncserver</code>，感觉很麻烦，而且还不一定能安装成功，我安装的VNC服务器端是<code>x11VNC</code>，按照步骤可以很顺利地完成安装，步骤如下： </p><h2 id="安装x11VNC软件包"><a href="#安装x11VNC软件包" class="headerlink" title="安装x11VNC软件包"></a>安装x11VNC软件包</h2><p><code>$ sudo  apt-get  install  x11vnc</code></p><h2 id="配置访问密码"><a href="#配置访问密码" class="headerlink" title="配置访问密码"></a>配置访问密码</h2><p><code>$ sudo  x11vnc  -storepasswd  /etc/x11vnc.pass</code></p><h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><p><code># vi  /lib/systemd/system/x11vnc.service      //粘贴一下代码，最后:wq 保存，请使用root用户，否则没有权限</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Start x11vnc at startup.</span><br><span class="line">After=multi-user.target</span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /etc/x11vnc.pass -rfbport 5900 -shared</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><h2 id="配置防火墙，配置和启动服务"><a href="#配置防火墙，配置和启动服务" class="headerlink" title="配置防火墙，配置和启动服务"></a>配置防火墙，配置和启动服务</h2><p><code># ufw allow 5900</code></p><p><code># systemctl enable x11vnc.service</code></p><p><code># systemctl daemon-reload</code></p><p>完成这四个步骤然后重启就可以了。（这个VNC的安装过程可以参考<a href="http://blog.csdn.net/longhr/article/details/51657610）" target="_blank" rel="noopener">http://blog.csdn.net/longhr/article/details/51657610）</a> </p><p>最后在你自己的电脑需要有一个vnc viewer的软件，可以在这里下载（链接：<a href="https://pan.baidu.com/s/1o8kPqXG" target="_blank" rel="noopener">https://pan.baidu.com/s/1o8kPqXG</a> 密码：v5r2） </p><h1 id="创建VM并配置相关信息"><a href="#创建VM并配置相关信息" class="headerlink" title="创建VM并配置相关信息"></a>创建VM并配置相关信息</h1><p>在安装好VNC后就可以登录服务器的远程桌面，打开一个terminal，在terminal中输入下面的命令可以打开Virtual Machine  Manager（注意，使用SSH远程登录服务器是无法打开virt-manager的界面的，一定要在登录了远程桌面后才能打开界面）</p><p><img src="https://img-blog.csdn.net/20171201233200479" alt="VMM"></p><p>使用Virtual Machine Manager的界面可以很方便的创建虚拟机，当然也可以在命令行中使用命令创建虚拟机，这个我就不在这里说了。 </p><h2 id="按照Openstack官网安装文档的主机网络配置两台虚拟机Controller和Compute"><a href="#按照Openstack官网安装文档的主机网络配置两台虚拟机Controller和Compute" class="headerlink" title="按照Openstack官网安装文档的主机网络配置两台虚拟机Controller和Compute"></a>按照Openstack官网安装文档的主机网络配置两台虚拟机Controller和Compute</h2><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/openstack%20network.png" alt="openstack network"></p><p>控制节点和计算节点这两个虚拟机分别两张网卡，一张配置为桥接模式，另一张配置为NAT模式。创建虚拟机时默认是添加一张网卡的，后面可以在虚拟机的硬件信息中添加。两张虚拟网卡的配置信息如图： </p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E7%BD%91%E5%8D%A1.png" alt="compute1"></p><p>上图显示的是桥接模式网卡的配置信息，Network source选择为<code>Bridge br0：Host device eth0</code> </p><p><img src="https://raw.githubusercontent.com/cao0507/Pictures/master/blog/NAT%E7%BD%91%E5%8D%A1.png" alt="NAT"></p><p>上图显示的是NAT模式网卡的配置信息，Network source选择为<code>Virtual network ‘default’：NAT</code> </p><p>这样按照官方文档部署双节点Openstack的前期准备工作就已经做完，后面就可以按照官方文档开始安装openstack了，祝你成功。附上官方文档链接<a href="https://docs.openstack.org/ocata/zh_CN/install-guide-ubuntu/index.html" target="_blank" rel="noopener">https://docs.openstack.org/ocata/zh_CN/install-guide-ubuntu/index.html</a> （注：这个是在ubuntu系统下安装Ocata版本Openstack中文文档） </p><hr>]]></content>
      
      <categories>
          
          <category> KVM </category>
          
          <category> Openstack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KVM </tag>
            
            <tag> Openstack </tag>
            
            <tag> vnc </tag>
            
            <tag> ubuntu </tag>
            
            <tag> Virtual Machine </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
