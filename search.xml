<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[虚拟化技术与云计算平台报告]]></title>
    <url>%2F2018%2F03%2F22%2F%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF%E4%B8%8E%E4%BA%91%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[前言从2006年谷歌首次提出“云计算”的概念到现在，云计算已经经历的十多年的发展，有众多厂商、组织和学者投入其中。一些云服务厂商有自己的云计算平台，但只是为客户提供云服务，外部开发者无法对这些厂商的云平台进行开发。另外也有一些组织机构或厂商开发的云计算平台是开源的，吸引大量开发者在这些开源平台上开展自己的工作。 目前，主流的开源云计算平台有很多种，本问将对这些平台进行调研以选择最适合于自己需求的平台。另外，虚拟化技术又是云计算的核心支撑技术，是将各种计算及存储资源充分整合和高效利用的关键技术，当前虚拟化技术也是多种多样，并且开源云计算平台往往又支持多种底层的虚拟化技术，因此也有必要对虚拟化技术进行调研，以选择最适合云平台和上层应用的虚拟化技术。综上，本报告的主要目标就是对多种虚拟化技术和多种开源云计算平台进行对比，以选出最满足需求的技术与平台。 本文将首先简单对比虚拟化与云计算。其后，由于虚拟化技术是云计算的基础，本报告将先对虚拟化技术展开论述，然后再对云计算平台进行论述。 虚拟化与云计算借助虚拟化技术，用户可以单个物理硬件系统为基础创建多个模拟环境或专用资源。并使用一款名为“Hypervisor”(虚拟机监控程序)的软件直接连接到硬件，从而将一个系统划分为不同的、单独安全环境，即虚拟机 (VM)。Hypervisor 能够将计算机资源与硬件分离并适当分配资源，而虚拟机则依赖这些功能运行。 云计算则由多种规则和方法组合而成，可以跨任何网络向用户按需提供计算、网络和存储基础架构资源、服务、平台和应用。这些基础架构资源、服务和应用来源于云。 简单来讲，云就是一系列管理及自动化软件编排而成的虚拟资源池，旨在帮助用户通过支持自动扩展和动态资源分配的自助服务门户，按需对这些资源进行访问。 下面对虚拟化与云计算做一个简单的对比： 虚拟化 云 定义 技术 方法论 目的 从一个物理硬件系统创建多个虚拟环境 汇聚并自动化分配虚拟资源以供按需使用 用途 针对具体用途为特定用户提供打包资源 针对多种用途为用户群组提供不同资源 使用寿命 数年（长期） 数小时至数月 成本 资本支出（CAPEX）高运营支出（OPEX）低 共有云：CAPEX高、OPEX低私有云：CAPEX低、OPEX高 可扩展性 纵向扩展 横向扩展 工作负载 有状态 无状态 租赁 单一租户 多个租户 虚拟化技术按照虚拟化的对象分类，虚拟化可分为服务器虚拟化、操作系统虚拟化、存储虚拟化、网络虚拟化等。其中服务器虚拟化对CPU、内存、设备与I/O这三种硬件资源的虚拟化技术已经相当成熟，但对GPU的虚拟化却还有很大的提升空间。下面将分别介绍服务器虚拟化中CPU虚拟化及GPU虚拟化相关的技术，然后对现在主流的虚拟化平台做一些比较。 一、CPU虚拟化目前，为了解决x86体系结构下的CPU虚拟化问题，业界提出了全虚拟化和半虚拟化两种不同的软件方案。除了通过软件的方式实现CPU虚拟化外，业界还提出了在硬件层添加支持功能的硬件辅助虚拟化方案来处理那些敏感的高级别指令。 全虚拟化在宿主机底层物理硬件与VM之间增加一个软件层，即虚拟机监控器（VMM或hypervisor），此时，VMM充当主机操作系统，用来管理不同的虚拟机，如图1所示。它隐藏了特定计算平台的实际物理特性，为用户提供抽象的、统一的、模拟的计算环境（称为虚拟机）。在VMM平台上，可以模拟出多套虚拟机，实现了在单机上运行多个不同类型操作系统的虚拟机。全虚拟化的优点是不需要修改客户机操作系统，因此支持多种操作系统，缺点是VMM层工作负荷较大，并占用一定的宿主机资源，性能不如裸机。主要代表有VMware vSphere，Microsoft公司的Virtual PC、Redhat公司的RED HAT ENTERPRISE VIRTUALIZATION等。 半虚拟化与全虚拟化类似，不同之处是需要修改客户机操作系统的核心代码，即增加一个专门的虚拟化应用程序接口，优化客户操作系统发出的指令，与VMM能够协同工作，以减轻VMM和宿主机的负担，进一步提升了虚拟机的性能，如图2所示。缺点是需要修改客户操作系统，影响了技术的普及。主要代表有使用开源虚拟化技术的Citrix的Xenserver、Microsoft的Hyper-V 。 为了更好地实现全、半虚拟化技术，Intel与AMD对传统X86架构进行改进，分别设计了Intel-VT和AMD-V CPU硬件辅助虚拟化技术。将原来的特权等级Ring 0、1、2、3 定义为Non-Root mode，新增了一个Root mode 特权等级（或称为Ring -1），这种情况下，OS 即可运行在原来Ring0 的等级，而VMM 则调整到更底层的Root Mode 等级，其架构如图3。硬件辅助虚拟化有效地解决了虚拟机效率低的问题，它使虚拟机可以运行ring 0 的指令，不用再进行操作系统的ring 切换，提高了虚拟机的整体效率。 现在主流的半、全虚拟化产品都支持硬件辅助虚拟化，代表有Oracle公司的VirtualBox、RHEV、VMware vSphere和Xneserver。 二、GPU虚拟化GPU虚拟化相关技术还垄断在少数厂商手中，并没有像CPU、内存、存储一样在开源社区推广普及。下面将介绍三大显卡厂商GPU虚拟化的发展。 NVIDIA，早在2013年，NVIDIA就推出了行业内第一款GPU虚拟化显卡GRID K1/K2，同期联合Citrix推出了商用的vGPU虚拟桌面解决方案，这比AMD提前了近3年。GPU虚拟化技术的出现，给一直被诟病性能不足的桌面虚拟化带来了转机。在2016年，NVIDIA推出第二款GPU虚拟化显卡，Maxwell架构的Tesla M6/M10/M60，新版的GRID将使用授权分为 3 个不同版本，依据版本不同收取额外软件授权使用费。 在2017年8月份NVIDIA推出了最新版GRID 5.0，虚拟化显卡新增Pascal架构的Tesla P4/P6/P40/P100，其中Quadro Virtual Datacenter Workstation版的授权支持vGPU在图形渲染模式和高性能计算模式之间切换，这是硬件厂商首次在vGPU层面将图形渲染和高性能计算进行了统一，又一次引领了行业趋势和市场需求。NVIDIA的虚拟化显卡只是硬件，还需要相应的服务器虚拟化系统的支持，这和Intel的CPU需要操作系统Windows和Linux来配合一样。现在只有Xen和ESXi能够支持GRID virtual GPU solution，被大量第三方厂商采用的KVM虚拟化平台还没有出现在GRID的支持列表中，因此可以说GPU另外一只脚还没能踏进云计算时代。2017年7月份NVIDIA和Nutanix宣布将合作在年底推出AHV版本的GRID，这算是KVM虚拟化走出了第 一步。在解决GPU虚拟化后，如何将虚拟机的画面传送到客户端，这是KVM虚拟化可以商用的第二步。KVM上默认配置的Spice协议对3D的支持并不好，Nutanix以及其他KVM方案解决商还需自行开发出可用的桌面传输协议，这才算是彻底完成了GRID在KVM上的应用。 AMD，AMD在NVIDIA推出GRID K1/K2 的两年半后才推出了自己的GPU虚拟化产品MxGPU，算是姗姗来迟。共有三款FirePro S系列的GPU支持MxGPU，一块GPU最多可以支持 32 个用户。当MxGPU上的虚拟机比较少时，能够达到图形工作站的性能。随着虚拟机数量增多，每个虚拟机获得的GPU性能逐步降低。有别于NVIDIA GRID通过软件实现的显卡虚拟化方式，AMD MxGPU是“全球首款基于硬件的虚拟化GPU解决方案”。MxGPU每个虚拟机能分得一定数量的独享流处理器和显存空间，这样可以避免不同虚拟机对GPU资源的抢夺，造成用户噪音。这种噪音问题直到今年8月底推出NVIDIA GRID 5. 0 才得到解决。MxGPU在定价上采用的是更符合买方逻辑的营销方法，只向用户收取需付硬件的购买费用。不过遗憾的是，目前只有VMware的ESXi支持MxGPU，Xen暂时只有技术验证版。没能同时支持两种主流化的虚拟化系统，一定程度上阻碍了MxGPU在市场的普及速度。Citrix的用户还是可以用过vSphere+XenDesktop的方案用上MxGPU，相比使用免费的XenServer，要多支付vSphere的费用。 Intel，Intel官方将不同的Intel GPU虚拟化技术分别命名为Intel GVT-s，Intel GVT-d和Intel GVT-g，分布对应API转发，直通，完全虚拟化。Intel GVT-g和NVIDIA vGPU类似，支持Xen/KVM平台，每个GPU最多能分享给7个用户同时使用。其中XenGT在 2016 年最早实现了业界的vGPU在线迁移，NVIDIA GRID直到这个季度才和Citrix合作完成了vGPU在线迁移。 2016 年的 2017 年2月份，Linux 4.10中加入Intel GVT-g for KVM。这是三大GPU厂商中，第一个支持KVM平台的完全虚拟化方案，意味着第三方采用KVM的云计算厂商终于有了一个可用的vGPU方案。不过Intel GPU虚拟化，由于核显性能的原因，只能满足图像密集型的用户体验，不能像GRID vGPU和MxGPU一样满足图形渲染的重度使用场景。Intel GPU虽然支持了大多数虚拟化桌面厂商使用的Xen/KVM两大类服务器虚拟化系统，可是硬件却和VDI高密度的使用场景不太搭。首先Intel的完全虚拟化只支持Broadwell架构以后的核芯显卡，作为VDI服务器中常用的Xeon E5/E7 v4 系列，以及第 一个的Xeon Scalable处理器，都没有核芯显卡。这在很大程度上限定了Intel GPU虚拟化在VDI的使用规模，有种落入有枪无弹的尴尬境地。 三、虚拟化平台比较服务器虚拟化技术日益成熟，并具有广泛的应用前景，目前有很多厂商进行虚拟化技术产品的开发和生产，包括：VMware、Microsoft、Citrix、IBM和RedHat等，其各自产品都有不同的特点，产品功能日益强大。下面将比较一下四种主流服务器虚拟化平台，如下表 ： VMware Xen KVM Hyper-V 厂商 VMware Citrix Red Hat Microsoft 是否免费 付费 开源免费 开源免费 付费 宿主机系统 WindowsLinux NetBSDLinuxSolaris Linux Windows server 2008及以上系统 客户机系统 Windows 2003、Windows 2008、RedHat、Debian、Ubuntu、Centos Xen-PV：纯Linux；Xen-HVM：支持Windows、Linux Linux、Windows Windows系列、Linux 支持技术 硬件辅助虚拟化（全虚拟化） 硬件辅助虚拟化（HVM全虚拟化、PV半虚拟化） 硬件辅助虚拟化（全虚拟化） 硬件辅助虚拟化（半虚拟化） 支持的vGPU产品 NVIDIA GRIDAMD MxGPU NVIDIA GRIDAMD MxGPU（技术验证版） Intel GVT-g for KVM 优点 相对成熟的商业软件，市场占有率较大 性能较好，支持半虚拟化 是内核本身的一部分，因此可以利用内核的优化和改进；高性能，稳定，无需修改客户机系统 对Windows的支持较好 缺点 不开源，费用较高 操作复杂，维护成本较高，目前已被RedHat抛弃 虚拟机性能比Xen略低 对Linux的支持较差，性能损失大 开源云计算平台Openstack对这四种虚拟化平台都有支持，默认使用的是KVM，Openstack与KVM结合的方案也已经相当成熟。另外，考虑到KVM是开源免费的虚拟化技术；宿主机系统支持绝大多数Linux系统，对于使用Linux系统的服务器都有很好的支持；而客户机操作系统不仅支持Linux，还支持Windows，可以满足绝大多数用户的需求，因此选择KVM作为Openstack底层的虚拟化技术的理由是很充分的。不过，KVM对于虚拟GPU的支持不是很好，只有Intel GVT-g for KVM可以支持KVM平台的全虚拟化方案，但是Intel GPU虚拟化由于核显性能的原因，只能满足图像密集型的用户体验，不能满足图形渲染等重度使用的场景。 云计算平台目前已经有多个云计算平台的开源实现，主要的开源云计算项目有Openstack、Eucalyptus、CloudStack和OpenNebula等，现比较如下： Openstack Eucalyptus CloudStack OpenNebula 发布时间 2010年7月 2008年5月 2010年5月 2008年7月 最新版本 Queens 4.4 4.11 5.4 授权协议 Apache v2.0 GPL v3.0 Apache v2.0 Apache v2.0 基本架构 Nova、Glance、Neutron、Keystone、Horizon、swift、Tacker等 Cloud Controller、Cluster Controller、Node Controller、Walrus、 Storage Controller 主要包括管理服务、云基础设施和网络三大部分 主要包括接口与API、用户与组、主机、网络、存储、集群6个部分 虚拟化技术支持 KVM、LXC、QEMU、UML、Vmware ESX/ESXi、Xen、Hyper-V Xen、KVM、ESXi KVM、Xen、ESXi、OVM、Baremetal Xen、KVM、Vmware 用户界面 Dashboard，较简单 web界面 Web Console，功能较完善 web界面 社区活跃程度 人数多，活跃用户数最多 人数多，但活跃用户数较少 人数少，但活跃用户数较多 人数较少，活跃用户数也少 兼容云平台 Amazon EC2，S3 Amazon EC2，S3 Amazon EC2，S3 Amazon EC2，S3 开发主导 开源社区 Eucalyptus System Inc Citrix公司 开源社区 主要支持厂商 160家左右，包括NASA、Rackspace、HP、Dell、UnitedStack等 亚马逊、戴尔、惠普、Intel、Redhat、Vmware等 不到60家，包括诺基亚、日本电话电报公司、阿尔卡特、迪士尼等 IBM、Akamai、Blackberry、Fuze、Telefonica、Indigital 官方文档 非常详细 不够详细 详细 详细 检测和审计 Telemetry Service Accounting system Event/Audit logs Accounting system、periodically-Monitoring 数据库 PostareSQL、MySQL、SQLite HyperSQL Database MySQL SQLite、MySQL 部署 私有云、共有云、混合云 私有云、混合云 私有云、共有云、混合云 私有云、共有云、混合云 操作系统 Debian 7.0、openSUSE、SUSE、Red Hat、CentOS、Fedora、Ubuntu CentOS、RHEL CentOS、RHEL6.3+、Ubuntu Red Hat、Ubuntu、SUSE、CentOS、Debian 开发语言 Python Java、C/C++ Java C、Ruby、shell 开源市场部署比例 69% 3% 14% 无统计数据 这四种主流的开源云计算平台都经过了近十年的发展，更新迭代了很多版本，能够从众多云计算平台的竞争中存活下来，都有相应的支持厂商和用户，说明它们各有各的特点，如在开发语言上就各有特色，Openstack使用的是Python语言，Eucalyptus使用Java、C/C++，CloudStack仅使用Java，而OpenNebula却显得比较奇怪，使用的是C语言、Ruby和shell，多种语言混杂而成。但不同平台之间还是有较大差距，从结果来看，在开源市场的部署比例，Openstack 69%的比例占据了绝对统治地位，Openstack能占据这样的地位有多方面的原因，如Openstack支持绝大多数的虚拟化技术，支持的操作系统也很多，使得Openstack具有广阔的应用范围；Openstack的官方文档非常详细，也降低了其学习成本；Openstack具有一个充满活力的开源社区，开发者不断为Openstack的发展作出贡献；OpenStack的支持厂商有160家左右，有如此多的厂商支持，给OpenStack的发展提供了根本保障。综合以上多方面的原因，本项目采用Openstack作为底层的云计算平台为上层提供基础设施资源也是理所当然的。另外，在2018年2月28日发布的Openstack Queens最新版本中，新引入的Marquee功能正是为了提供对vGPU的内置支持能力，这意味着用户能够将GPU添加至虚拟机中，为本项目的上层应用，如深度学习等需要强大GPU运算能力的应用提供了支持。 总结通过以上的分析，能够清楚的了解各种虚拟化技术及各种云计算平台的差异，对于要选择满足自己需求的技术与平台会有一些帮助。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>Openstack</tag>
        <tag>云计算</tag>
        <tag>虚拟化</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack环境下手动安装Mistral]]></title>
    <url>%2F2017%2F12%2F23%2FOpenstack%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85Mistral%2F</url>
    <content type="text"><![CDATA[概述在openstack平台中能够成功安装Tacker，但是安装的Tacker并不能用，因为在tacker中创建VIM时需要调用Mistral工作流组件。因此本文就来介绍在openstack环境中手动安装Mistral的过程。 注： 安装的openstack是在Ubuntu 16.04系统下的Ocata版本；本文中涉及的密码都统一设置成 “openstack”。 参考官方文档 一、安装必要组件12$ apt-get install python-dev python-setuptools python-pip libffi-dev \ libxslt1-dev libxml2-dev libyaml-dev libssl-dev 二、安装Mistral server1、下载Mistral源码，并进入下载目录$ git clone https://github.com/openstack/mistral.git $ cd mistral 2、安装Mistral环境依赖包$ pip install -r requirements.txt 3、安装Mistral$ python setup.py install 4、生成配置文件$ oslo-config-generator --config-file tools/config/config-generator.mistral.conf --output-file etc/mistral.conf 5、创建Mistral日志文件和配置文件夹# mkdir -p /etc/mistral /var/log/mistral 6、复制配置文件到配置文件夹# cp etc/* /etc/mistral/ 7、修改配置文件123456789101112131415# vi /etc/mistral/mistral.conf [keystone_authtoken]auth_uri = http://controller:5000auth_version = 3identity_uri = http://controller:35357/admin_user = adminadmin_password = openstackadmin_tenant_name = admin[database]connection = mysql+pymysql://mistral:openstack@controller/mistral [DEFAULT]transport_url = rabbit://openstack:openstack@controller 8、创建数据库123456# mysqlMariaDB [(none)]&gt; CREATE DATABASE mistral;MariaDB [mistral]&gt; GRANT ALL PRIVILEGES ON mistral.* TO &apos;mistral&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;openstack&apos;;MariaDB [mistral]&gt; GRANT ALL PRIVILEGES ON mistral.* TO &apos;mistral&apos;@&apos;%&apos; IDENTIFIED BY &apos;openstack&apos;;MariaDB [mistral]&gt; flush privileges;MariaDB [mistral]&gt; exit; 9、创建服务和endpoint1234$ openstack service create --name mistral --description &quot;Openstack Workflow service&quot; workflow$ openstack endpoint create --region RegionOne workflow public http://controller:8989/v2$ openstack endpoint create --region RegionOne workflow internal http://controller:8989/v2$ openstack endpoint create --region RegionOne workflow admin http://controller:8989/v2 10、初始化数据库信息12345678910111213141516171819202122232425root@controller:/home/openstack# mistral-db-manage --config-file /etc/mistral/mistral.conf upgrade headINFO [alembic.runtime.migration] Context impl MySQLImpl.INFO [alembic.runtime.migration] Will assume non-transactional DDL.INFO [alembic.runtime.migration] Running upgrade -&gt; 001, Kilo releaseINFO [alembic.runtime.migration] Running upgrade 001 -&gt; 002, KiloINFO [alembic.runtime.migration] Running upgrade 002 -&gt; 003, cron_trigger_constraintsINFO [alembic.runtime.migration] Running upgrade 003 -&gt; 004, add description for executionINFO [alembic.runtime.migration] Running upgrade 004 -&gt; 005, Increase executions_v2 column size from JsonDictType to JsonLongDictTypeINFO [alembic.runtime.migration] Running upgrade 005 -&gt; 006, add a Boolean column &apos;processed&apos; to the table delayed_calls_v2INFO [alembic.runtime.migration] Running upgrade 006 -&gt; 007, Move system flag to base definitionINFO [alembic.runtime.migration] Running upgrade 007 -&gt; 008, Increase size of state_info column from String to TextINFO [alembic.runtime.migration] Running upgrade 008 -&gt; 009, Add database indicesINFO [alembic.runtime.migration] Running upgrade 009 -&gt; 010, add_resource_members_v2_tableINFO [alembic.runtime.migration] Running upgrade 010 -&gt; 011, add workflow id for executionINFO [alembic.runtime.migration] Running upgrade 011 -&gt; 012, add event triggers tableINFO [alembic.runtime.migration] Running upgrade 012 -&gt; 013, split_execution_table_increase_namesINFO [alembic.runtime.migration] Running upgrade 013 -&gt; 014, fix_past_scripts_discrepanciesINFO [alembic.runtime.migration] Running upgrade 014 -&gt; 015, add_unique_keys_for_non_locking_modelINFO [alembic.runtime.migration] Running upgrade 015 -&gt; 016, Increase size of task_executions_v2.unique_keyINFO [alembic.runtime.migration] Running upgrade 016 -&gt; 017, Add named lock tableINFO [alembic.runtime.migration] Running upgrade 017 -&gt; 018, increate_task_execution_unique_key_sizeINFO [alembic.runtime.migration] Running upgrade 018 -&gt; 019, Change scheduler schema.INFO [alembic.runtime.migration] Running upgrade 019 -&gt; 020, add type to task executionINFO [alembic.runtime.migration] Running upgrade 020 -&gt; 021, Increase environments_v2 column size from JsonDictType to JsonLongDictType 11、添加自带的action123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172root@controller:/home/openstack# mistral-db-manage --config-file /etc/mistral/mistral.conf populate*输出结果可能为：*No handlers could be found for logger &quot;mistral.actions.openstack.action_generator.base&quot;*也可能会出错：*……2017-12-22 22:21:24.486 16802 INFO mistral.actions.openstack.action_generator.base [-] Processing OpenStack action mapping from file: /usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/mapping.json2017-12-22 22:21:24.551 16802 INFO mistral.actions.openstack.action_generator.base [-] Processing OpenStack action mapping from file: /usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/mapping.json2017-12-22 22:21:24.761 16802 INFO mistral.actions.openstack.action_generator.base [-] Processing OpenStack action mapping from file: /usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/mapping.json2017-12-22 22:21:24.878 16802 INFO mistral.actions.openstack.action_generator.base [-] Processing OpenStack action mapping from file: /usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/mapping.json2017-12-22 22:21:24.883 16802 WARNING oslo_config.cfg [-] Option &quot;auth_uri&quot; from group &quot;keystone_authtoken&quot; is deprecated for removal (The auth_uri option is deprecated in favor of www_authenticate_uri and will be removed in the S release.). Its value may be silently ignored in the future.^C2017-12-22 22:21:25.382 16802 CRITICAL Mistral [-] Unhandled error: KeyboardInterrupt2017-12-22 22:21:25.382 16802 ERROR Mistral Traceback (most recent call last):2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/bin/mistral-db-manage&quot;, line 10, in &lt;module&gt;2017-12-22 22:21:25.382 16802 ERROR Mistral sys.exit(main())2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/db/sqlalchemy/migration/cli.py&quot;, line 137, in main2017-12-22 22:21:25.382 16802 ERROR Mistral CONF.command.func(config, CONF.command.name)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/db/sqlalchemy/migration/cli.py&quot;, line 75, in do_populate2017-12-22 22:21:25.382 16802 ERROR Mistral action_manager.sync_db()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/services/action_manager.py&quot;, line 80, in sync_db2017-12-22 22:21:25.382 16802 ERROR Mistral register_action_classes()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/services/action_manager.py&quot;, line 126, in register_action_classes2017-12-22 22:21:25.382 16802 ERROR Mistral _register_dynamic_action_classes()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/services/action_manager.py&quot;, line 86, in _register_dynamic_action_classes2017-12-22 22:21:25.382 16802 ERROR Mistral actions = generator.create_actions()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/action_generator/base.py&quot;, line 143, in create_actions2017-12-22 22:21:25.382 16802 ERROR Mistral client_method = class_.get_fake_client_method()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/base.py&quot;, line 75, in get_fake_client_method2017-12-22 22:21:25.382 16802 ERROR Mistral return cls._get_client_method(cls._get_fake_client())2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/mistral/actions/openstack/actions.py&quot;, line 380, in _get_fake_client2017-12-22 22:21:25.382 16802 ERROR Mistral return cls._get_client_class()(session=sess)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/ironic_inspector_client/v1.py&quot;, line 88, in __init__2017-12-22 22:21:25.382 16802 ERROR Mistral super(ClientV1, self).__init__(**kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/ironic_inspector_client/common/http.py&quot;, line 134, in __init__2017-12-22 22:21:25.382 16802 ERROR Mistral region_name=region_name)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/session.py&quot;, line 856, in get_endpoint2017-12-22 22:21:25.382 16802 ERROR Mistral return auth.get_endpoint(self, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/identity/base.py&quot;, line 212, in get_endpoint2017-12-22 22:21:25.382 16802 ERROR Mistral service_catalog = self.get_access(session).service_catalog2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/identity/base.py&quot;, line 136, in get_access2017-12-22 22:21:25.382 16802 ERROR Mistral self.auth_ref = self.get_auth_ref(session)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/identity/generic/base.py&quot;, line 198, in get_auth_ref2017-12-22 22:21:25.382 16802 ERROR Mistral return self._plugin.get_auth_ref(session, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/identity/v3/base.py&quot;, line 167, in get_auth_ref2017-12-22 22:21:25.382 16802 ERROR Mistral authenticated=False, log=False, **rkwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/session.py&quot;, line 766, in post2017-12-22 22:21:25.382 16802 ERROR Mistral return self.request(url, &apos;POST&apos;, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/positional/__init__.py&quot;, line 101, in inner2017-12-22 22:21:25.382 16802 ERROR Mistral return wrapped(*args, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/session.py&quot;, line 616, in request2017-12-22 22:21:25.382 16802 ERROR Mistral resp = send(**kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/dist-packages/keystoneauth1/session.py&quot;, line 674, in _send_request2017-12-22 22:21:25.382 16802 ERROR Mistral resp = self.session.request(method, url, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/requests/sessions.py&quot;, line 508, in request2017-12-22 22:21:25.382 16802 ERROR Mistral resp = self.send(prep, **send_kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/requests/sessions.py&quot;, line 618, in send2017-12-22 22:21:25.382 16802 ERROR Mistral r = adapter.send(request, **kwargs)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/requests/adapters.py&quot;, line 440, in send2017-12-22 22:21:25.382 16802 ERROR Mistral timeout=timeout2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/urllib3/connectionpool.py&quot;, line 601, in urlopen2017-12-22 22:21:25.382 16802 ERROR Mistral chunked=chunked)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/local/lib/python2.7/dist-packages/urllib3/connectionpool.py&quot;, line 380, in _make_request2017-12-22 22:21:25.382 16802 ERROR Mistral httplib_response = conn.getresponse(buffering=True)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/httplib.py&quot;, line 1136, in getresponse2017-12-22 22:21:25.382 16802 ERROR Mistral response.begin()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/httplib.py&quot;, line 453, in begin2017-12-22 22:21:25.382 16802 ERROR Mistral version, status, reason = self._read_status()2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/httplib.py&quot;, line 409, in _read_status2017-12-22 22:21:25.382 16802 ERROR Mistral line = self.fp.readline(_MAXLINE + 1)2017-12-22 22:21:25.382 16802 ERROR Mistral File &quot;/usr/lib/python2.7/socket.py&quot;, line 480, in readline2017-12-22 22:21:25.382 16802 ERROR Mistral data = self._sock.recv(self._rbufsize)2017-12-22 22:21:25.382 16802 ERROR Mistral KeyboardInterrupt2017-12-22 22:21:25.382 16802 ERROR Mistral 纠结了很久后发现这些都不用太在意，直接跳过，哈哈！ 三、安装Mistral client1、下载Mistral-client源码$ git clone git://git.openstack.org/openstack/python-mistralclient.git -b stable/ocata $ cd python-mistralclient 2、安装Mistral-client模块$ pip install -r requirements.txt $ python setup.py install 四、安装Mistral horizon1、下载Mistral-horizon源码$ git clone https://git.openstack.org/openstack/mistral-dashboard.git -b stable/ocata $ cd mistral-dashboard/ 2、安装Mistral-horizon模块$ pip install -r requirements.txt $ python setup.py install 3、复制一个文件# cp -b mistraldashboard/enabled/_50_mistral.py /usr/share/openstack-dashboard/openstack_dashboard/enabled/_50_mistral.py 4、重启apache2服务# service apache2 restart 安装好Mistral-horizon后，admin用户登录dashboard界面就可以看到Mistral相关的workflow，如图： 五、运行Mistral server运行下面的第一条命令：12345678910111213141516171819202122232425262728root@controller:/home/openstack/mistral# python mistral/cmd/launch.py --server all --config-file /etc/mistral/mistral.conf|\\ //| || ||||\\ //|| __ || __ __ |||| \\// || || // |||||| || \\ // \\ |||| \/ || \\ || || || \\ |||| || || \\ || || || /\\ |||| || || __// ||_// || \\__// \\_ ||Mistral Workflow Service, version 6.0.0Launching server components [engine,event-engine,api,executor]...2017-12-22 22:42:58.373 16966 INFO mistral.event_engine.default_event_engine [-] Starting event notification task...2017-12-22 22:42:58.571 16966 INFO mistral.event_engine.default_event_engine [-] Found 0 event triggers./usr/local/lib/python2.7/dist-packages/oslo_messaging/server.py:341: FutureWarning: blocking executor is deprecated. Executor default will be removed. Use explicitly threading or eventlet instead in version &apos;pike&apos; and will be removed in version &apos;rocky&apos; category=FutureWarning)2017-12-22 22:42:58.913 16966 WARNING oslo_config.cfg [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] Option &quot;auth_uri&quot; from group &quot;keystone_authtoken&quot; is deprecated for removal (The auth_uri option is deprecated in favor of www_authenticate_uri and will be removed in the S release.). Its value may be silently ignored in the future.2017-12-22 22:42:58.915 16966 WARNING oslo_config.cfg [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] Option &quot;auth_uri&quot; from group &quot;keystone_authtoken&quot; is deprecated. Use option &quot;www_authenticate_uri&quot; from group &quot;keystone_authtoken&quot;.2017-12-22 22:42:58.925 16966 WARNING keystonemiddleware.auth_token [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] AuthToken middleware is set with keystone_authtoken.service_token_roles_required set to False. This is backwards compatible but deprecated behaviour. Please set this to True.2017-12-22 22:42:58.926 16966 WARNING keystonemiddleware.auth_token [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] Use of the auth_admin_prefix, auth_host, auth_port, auth_protocol, identity_uri, admin_token, admin_user, admin_password, and admin_tenant_name configuration options was deprecated in the Mitaka release in favor of an auth_plugin and its related options. This class may be removed in a future release.2017-12-22 22:42:58.931 16966 INFO oslo.service.wsgi [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] mistral_api listening on 0.0.0.0:89892017-12-22 22:42:58.932 16966 INFO oslo_service.service [req-46885c1b-de53-4bba-958d-97484cd17783 - - - - -] Starting 4 workersAPI server started.API server started.API server started.API server started.Event engine server started.Executor server started.Engine server started. 六、测试一下Mistral是否可用12345678910111213openstack@controller:~/mistral/etc$ mistral workbook-list+--------+--------+------------+------------+| Name | Tags | Created at | Updated at |+--------+--------+------------+------------+| &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; |+--------+--------+------------+------------+openstack@controller:~/mistral/etc$ mistral action-list+--------+--------+-----------+--------+-------------+--------+------------+------------+| ID | Name | Is system | Input | Description | Tags | Created at | Updated at |+--------+--------+-----------+--------+-------------+--------+------------+------------+| &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; | &lt;none&gt; |+--------+--------+-----------+--------+-------------+--------+------------+------------+ OK，成功了，开心！！！]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>Openstack</tag>
        <tag>Tacker</tag>
        <tag>Mistral</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Openstack环境下手动安装Tacker]]></title>
    <url>%2F2017%2F12%2F23%2FOpenstack%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85Tacker%2F</url>
    <content type="text"><![CDATA[概述本文参考官方文档，在现有的openstack平台上，手动安装Tacker。基础的openstack平台包含了最核心的keystone、glance、nova、neutron、horizon这5个组件，但是Tacker还需要预先安装好Mistral和Barbican这两个组件，在安装好这两个组件后就可以开始按照以下步骤安装Tacker了。参考：官方文档链接 注： 本文涉及到的密码都统一设置成openstack。 一、安装Tacker server1、创建数据库12345# mysqlMariaDB [(none)]&gt; CREATE DATABASE tacker;MariaDB [tacker]&gt; GRANT ALL PRIVILEGES ON tacker.* TO &apos;tacker&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;openstack&apos;;MariaDB [tacker]&gt; GRANT ALL PRIVILEGES ON tacker.* TO &apos;tacker&apos;@&apos;%&apos; IDENTIFIED BY &apos;openstack&apos;;MariaDB [tacker]&gt; exit; 2、创建user、role、endpoints1)获得admin凭证# . admin-openrc 2)创建tacker用户，密码为openstack# openstack user create --domain default --password openstack tacker 3)给tacker用户赋予admin权限# openstack role add --project service --user tacker admin 4)创建tacker服务# openstack service create --name tacker \ --description &quot;Tacker Project&quot; nfv-orchestration 5)创建endpoints123456# openstack endpoint create --region RegionOne nfv-orchestration \ public http://controller:9890/# openstack endpoint create --region RegionOne nfv-orchestration \ internal http://controller:9890/# openstack endpoint create --region RegionOne nfv-orchestration \ admin http://controller:9890/ 3、下载Tacker源码# git clone https://github.com/openstack/tacker -b stable/ocata 4、安装Tacker环境依赖包# cd tacker # pip install -r requirements.txt 5、安装Tacker# python setup.py install 6、创建Tacker日志文件夹# mkdir -p /var/log/tacker 7、生成配置文件# ./tools/generate_config_file_sample.sh 这时生成的配置文件在etc/tacker/tacker.conf.sample，需要将其重命名为tacker.conf # mv etc/tacker/tacker.conf.sample etc/tacker/tacker.conf 8、修改配置文件1234567891011121314151617181920212223242526272829303132333435363738# vi etc/tacker/tacker.conf[DEFAULT]auth_strategy = keystonepolicy_file = /usr/local/etc/tacker/policy.jsondebug = Trueuse_syslog = Falsebind_host = 10.0.0.11bind_port = 9890service_plugins = nfvo,vnfmstate_path = /var/lib/tacker...[nfvo]vim_drivers = openstack[keystone_authtoken]memcached_servers = 11211region_name = RegionOneauth_type = passwordproject_domain_name = Defaultuser_domain_name = Defaultusername = tackerproject_name = servicepassword = openstackauth_url = http://controller:35357auth_uri = http://controller:5000...[agent]root_helper = sudo /usr/local/bin/tacker-rootwrap /usr/local/etc/tacker/rootwrap.conf[database]connection = mysql://tacker:openstack@controller:3306/tacker?charset=utf8[tacker]monitor_driver = ping,http_ping 9、复制配置文件到配置文件夹# cp etc/tacker/tacker.conf /usr/local/etc/tacker/ 10、初始化数据库信息# /usr/local/bin/tacker-db-manage --config-file /usr/local/etc/tacker/tacker.conf upgrade head 二、安装Tacker client1、下载Tacker-client源码# git clone https://github.com/openstack/python-tackerclient -b stable/ocata 2、安装Tacker-client模块# cd python-tackerclient # python setup.py install 三、安装Tacker horizon1、下载Tacker-horizon源码# git clone https://github.com/openstack/tacker-horizon -b stable/ocata 2、安装Tacker-horizon模块# cd tacker-horizon # python setup.py install 安装好tacker-horizon后，admin用户登录dashboard界面就可以看到Tacker相关的VNFM和NFVO，如图： 四、开启Tacker server打开一个新的终端，开启Tacker-server，因为Tacker-server的程序会独占这个终端。123sudo python /usr/local/bin/tacker-server \ --config-file /usr/local/etc/tacker/tacker.conf \ --log-file /var/log/tacker/tacker.log 需注意的一个问题： 在安装完Tacker而没有装Mistral时创建VIM的结果如下：1234root@controller:/home/openstack# tacker vim-register --is-default --config-file config.yaml test_vimThe resource could not be found.或者是这种错误：Expecting to find domain in project. The server could not comply with the request since it is either malformed or otherwise incorrect. The client is assumed to be in error. 经过查阅资料，知道这个问题是因为Tacker在创建VIM时要调用Mistral而造成的。所以在使用tacker之前需要先安装好Mistral（可以在安装tacker前安装Mistral，也可以在tacker安装之后安装Mistral，后续还需继续了解）。]]></content>
      <categories>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>Openstack</tag>
        <tag>Tacker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM虚拟机部署openstack的网络配置]]></title>
    <url>%2F2017%2F12%2F03%2FKVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%83%A8%E7%BD%B2openstack%E7%9A%84%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[概述这篇文章记录的是按照官方文档在KVM环境下部署双节点openstack过程中，前期准备KVM环境和网络配置相关的内容，在完成这篇博客涉及到的工作之后就可以按照官方文档手动安装openstack了。本文涉及的主要工作，首先是在服务器的ubuntu 16.04 desktop版系统上搭建kvm环境，然后在服务器上安装VNC远程桌面，最后在KVM环境中开启两台虚拟机，分别两张网卡，第一张网卡使用桥接模式，第二张网卡使用NAT模式。下面开始介绍一下这个过程。 服务器搭建KVM环境查看CPU是否支持KVM$ egrep -c &quot;(svm|vmx)&quot; /proc/cpuinfo 输出结果大于0证明CPU支持KVM虚拟化 安装KVM及相关依赖包$ sudo apt-get install qemu-kvm qemu virt-manager virt-viewer libvirt-bin bridge-utils 启用桥接网络在服务器上启用桥接网络需要配置一个桥接设备br0，配置br0有两种方式，通过手动配置和通过修改文件配置。 通过手动配置 创建br0网桥 # brctl addbr br0 将eth0网卡添加到br0上，此时可能会断网 # brctl addif br0 eth0 删除eth0上的IP地址 # ip addr del dev eth0 192.168.1.25/24 配置br0的IP地址并启动br0网桥设备 # ifconfig br0 192.168.1.25/24 up 重新加入默认网关 # route add default gw 192.168.1.1 查看配置是否生效 12345# route //查看默认网关，输出结果如下Kernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Ifacedefault 192.168.1.1 0.0.0.0 UG 0 0 0 br0192.168.1.0 * 255.255.255.0 U 0 0 0 br0 123456789101112131415161718192021222324252627# ifconfig //查看eth0和br0的IP信息，输出结果如下，可以发现现在br0有IP而eth0没有IP了br0 Link encap:Ethernet HWaddr 00:e0:81:e2:3c:3d inet addr:192.168.1.25 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::2e0:81ff:fee2:3c3d/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:1316822 errors:0 dropped:5787 overruns:0 frame:0 TX packets:365475 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:581279124 (581.2 MB) TX bytes:562586852 (562.5 MB) eth0 Link encap:Ethernet HWaddr 00:e0:81:e2:3c:3d inet6 addr: fe80::2e0:81ff:fee2:3c3d/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6671034 errors:0 dropped:9627 overruns:0 frame:0 TX packets:840972 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1346523816 (1.3 GB) TX bytes:614510541 (614.5 MB) Memory:dfb80000-dfbfffff lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:1450290 errors:0 dropped:0 overruns:0 frame:0 TX packets:1450290 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:24027042487 (24.0 GB) TX bytes:24027042487 (24.0 GB) 这就是通过手动来配置桥接设备br0的方法，这种方法在配置好之后马上就生效了，但是在系统重启之后这些配置信息都会被清除，要想使配置永久生效则需要修改网络配置文件，也就是下面的方法。 通过修改文件配置 修改前先将网络配置文件进行备份 # cp /etc/network/interfaces /etc/network/interfaces.bak 修改网络配置文件/etc/network/interfaces # vi /etc/network/interfaces //修改结果如下 1234567891011121314auto loiface lo inet loopback # Enabing Bridge networking br0 interfaceauto br0iface br0 inet staticaddress 192.168.1.25network 192.168.1.0netmask 255.255.255.0broadcast 192.168.1.255gateway 192.168.1.1dns-nameservers 223.5.5.5bridge_ports eth0bridge_stp off 保存后退出，关机重启中配置文件就生效了。这种方法只需要修改配置文件然后重启就可以，比较简单，而且是永久生效，比较符合我们的需求，因为我们的虚拟机通过桥接模式连接外网的话都是连接到br0上的。 修改virbr0的网段在服务器上安装好虚拟化软件后，KVM会自动生成一个virbr0的桥接设备，它的作用是为连接其上的虚拟网卡提供NAT访问外网的功能，并提供DHCP服务。virbr0默认分配的IP是192.168.122.1，使用 ifconfig 命令查看得virbr0的信息如下： 12345678910$ ifconfig…… virbr0 Link encap:Ethernet HWaddr 52:54:00:f8:70:e3 inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 在这种情况下，连接到virbr0上的虚拟机的虚拟网卡也是在192.168.122.0网段上的，如果让连接到virbr0上的虚拟网卡在自定义的网段上就需要修改virbr0的网段，修改方法如下： # virsh net-edit default 123456789101112&lt;network&gt; &lt;name&gt;default&lt;/name&gt; &lt;uuid&gt;91cc230a-bf53-487c-b296-10323705d7e8&lt;/uuid&gt; &lt;forward mode=&apos;nat&apos;/&gt; &lt;bridge name=&apos;virbr0&apos; stp=&apos;on&apos; delay=&apos;0&apos;/&gt; &lt;mac address=&apos;52:54:00:f8:70:e3&apos;/&gt; &lt;ip address=&apos;10.0.0.1&apos; netmask=&apos;255.255.255.0&apos;&gt; &lt;dhcp&gt; &lt;range start=&apos;10.0.0.2&apos; end=&apos;10.0.0.254&apos;/&gt; &lt;/dhcp&gt; &lt;/ip&gt;&lt;/network&gt; 这样就将virbr0的网段改成10.0.0.0/24，连接到virbr0的虚拟网卡的IP将会在10.0.0.2/24 - 10.0.0.254/24范围内自动分配一个。如果有需要可以自己手动给虚拟网卡配置IP并写到配置文件中去。 服务器安装VNC远程桌面因为服务器上安装的Ubuntu 16.04 LTS desktop版的系统，在后续的工作中需要远程登录到服务器，虽然可以通过SSH远程管理服务器，但是可视化的界面往往会给新手用户提供很大的便利，所以可以在服务器上安装VNC。开始在服务器上安装VNC试过很多方法，VNC服务器端也有多种选择，如VNC4server、tigervncserver，感觉很麻烦，而且还不一定能安装成功，我安装的VNC服务器端是x11VNC，按照步骤可以很顺利地完成安装，步骤如下： 安装x11VNC软件包$ sudo apt-get install x11vnc 配置访问密码$ sudo x11vnc -storepasswd /etc/x11vnc.pass 创建服务# vi /lib/systemd/system/x11vnc.service //粘贴一下代码，最后:wq 保存，请使用root用户，否则没有权限 12345678[Unit]Description=Start x11vnc at startup.After=multi-user.target[Service]Type=simpleExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /etc/x11vnc.pass -rfbport 5900 -shared[Install]WantedBy=multi-user.target 配置防火墙，配置和启动服务# ufw allow 5900 # systemctl enable x11vnc.service # systemctl daemon-reload 完成这四个步骤然后重启就可以了。（这个VNC的安装过程可以参考http://blog.csdn.net/longhr/article/details/51657610） 最后在你自己的电脑需要有一个vnc viewer的软件，可以在这里下载（链接：https://pan.baidu.com/s/1o8kPqXG 密码：v5r2） 创建VM并配置相关信息在安装好VNC后就可以登录服务器的远程桌面，打开一个terminal，在terminal中输入下面的命令可以打开Virtual Machine Manager（注意，使用SSH远程登录服务器是无法打开virt-manager的界面的，一定要在登录了远程桌面后才能打开界面） 使用Virtual Machine Manager的界面可以很方便的创建虚拟机，当然也可以在命令行中使用命令创建虚拟机，这个我就不在这里说了。 按照Openstack官网安装文档的主机网络配置两台虚拟机Controller和Compute 控制节点和计算节点这两个虚拟机分别两张网卡，一张配置为桥接模式，另一张配置为NAT模式。创建虚拟机时默认是添加一张网卡的，后面可以在虚拟机的硬件信息中添加。两张虚拟网卡的配置信息如图： 上图显示的是桥接模式网卡的配置信息，Network source选择为Bridge br0：Host device eth0 上图显示的是NAT模式网卡的配置信息，Network source选择为Virtual network ‘default’：NAT 这样按照官方文档部署双节点Openstack的前期准备工作就已经做完，后面就可以按照官方文档开始安装openstack了，祝你成功。附上官方文档链接https://docs.openstack.org/ocata/zh_CN/install-guide-ubuntu/index.html （注：这个是在ubuntu系统下安装Ocata版本Openstack中文文档）]]></content>
      <categories>
        <category>KVM</category>
        <category>Openstack</category>
      </categories>
      <tags>
        <tag>Openstack</tag>
        <tag>KVM</tag>
        <tag>vnc</tag>
        <tag>ubuntu</tag>
        <tag>Virtual Machine</tag>
      </tags>
  </entry>
</search>
